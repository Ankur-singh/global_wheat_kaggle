cp_path: saved/weights/
logs_path: saved/logs

trainer:
    gpus: 1
    accumulate_grad_batches: 8
    gradient_clip_val: 0.5
    max_epochs: 10
    fast_dev_run: False
    auto_lr_find: False

data:
    train_folds: train_folds.csv
    train_ext: train_ext.csv
    path: data
    fold: 0
    img_sz: 640
    batch_size: 2
    num_workers: 2

scheduler:
    class_name: torch.optim.lr_scheduler.ReduceLROnPlateau
    params:
        mode: min
        factor: 0.5
        patience: 1
        verbose: False
        threshold: 0.0001
        threshold_mode: abs
        cooldown: 0 
        min_lr: 1e-8
        eps: 1e-08
    step: epoch
    monitor: val_loss  

optimizer:
    class_name: torch.optim.Adam
    params:
        weight_decay: 0.005
        lr: 0.002
